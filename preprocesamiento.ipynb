{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento datos Alquiler AMBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División del dataset\n",
    "\n",
    "Agrego datos realcionados a al media del precio del dataset de TRAIN para evitar Data Leakage.\n",
    "Hago mean encoding para ITE_ADD_NEIGHBORHOOD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el archivo a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"path_toia = '/Users/victoria/Desktop/alquiler_AMBA_dev.csv'\"\n",
    "path_toia = '/Users/benjavitale/Documents/ML/TP_F/alquiler_AMBA_dev.csv'\n",
    "df_original = pd.read_csv(path_toia, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_toia, low_memory=False)\n",
    "filas, columnas = df.shape\n",
    "print(f\"El dataset tiene {filas} filas y {columnas} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos faltantes por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faltantes = df.isnull().sum()\n",
    "print(faltantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se eliminan las filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(f\"Cantidad de filas después de eliminar duplicadas: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Eliminacion de columnas\n",
    "Las columnas Longitud, Latitud y id_grid no van a ser necesarias para la implementacion del modelo ya que o contienen informacion redundante o demasiados abstracta para agregar precision de prediccion.\n",
    "\n",
    "Por otro lado optamos por eliminar la columna STATE_NAME ya que esta es muy parecida a la columna CITY_NAME la cual es mas precisa pero aun asi mostrando valores muy similares. Para no aprender lo mismo sacamos la menos precisa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['LONGITUDE'], inplace=True)\n",
    "df.drop(columns=['LATITUDE'], inplace=True)\n",
    "df.drop(columns=['id_grid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MesListing\n",
    "Se cambia a tipo de dato datetime. No hay valores faltantes. Tipo de datos: datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MesListing'] = pd.to_datetime(df['MesListing'])\n",
    "df['anio'] = df['MesListing'].dt.year\n",
    "df['mes'] = df['MesListing'].dt.month\n",
    "df['dia'] = df['MesListing'].dt.day\n",
    "df = df.drop(columns=['MesListing']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. TIPOPROPIEDAD\n",
    "Se elimina la columna ya que son todos departamentos y no agrega información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIPOPROPIEDAD'].unique()\n",
    "df.drop(columns=['TIPOPROPIEDAD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. STotalM2\n",
    "Había 20 valores faltantes. Se eliminaron estas filas ya que no eran representativas. Hay otros 8227 valores que dice 00 que no tiene sentido por lo que se lo reemplaza con la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['STotalM2'])\n",
    "filas, columnas = df.shape\n",
    "print(f\"El dataset tiene {filas} filas y {columnas} columnas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ceros = df[df['STotalM2'] == 0]\n",
    "print(df_ceros)\n",
    "media_stotalm2 = df.loc[df['STotalM2'] > 0, 'STotalM2'].mean()\n",
    "df['STotalM2'] = df['STotalM2'].replace(0, media_stotalm2)\n",
    "print(f\"Cantidad de valores igual a cero en STotalM2 después de imputar: {(df['STotalM2'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. SConstrM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_stotalm2 = df.loc[df['SConstrM2'] > 0, 'SConstrM2'].mean()\n",
    "df['SConstrM2'] = df['SConstrM2'].replace(0, media_stotalm2)\n",
    "print(f\"Cantidad de valores igual a cero en STotalM2 después de imputar: {(df['SConstrM2'] == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Dormitorios\n",
    "Se borrarlon las filas con dormitorios> 40. Para los que estan entre 40 y 20 se analizó los M2 construídos y si tenía al menos 400 se conservó y sino se eliminó. Se eliminaron las filas con 0 dormitorios y 0 ambientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_superficie = 400\n",
    "df_filtrar = df[(df['Dormitorios'] >= 20) & (df['Dormitorios'] <= 40)]\n",
    "a_eliminar = df_filtrar[df_filtrar['STotalM2'] < umbral_superficie]\n",
    "print(f\"Cantidad de filas eliminadas por STotalM2 menor a {umbral_superficie}: {len(a_eliminar)}\")\n",
    "df = df[~((df['Dormitorios'] >= 20) & (df['Dormitorios'] <= 40) & (df['STotalM2'] < umbral_superficie))]\n",
    "df = df[~((df['Dormitorios'] == 0) & (df['Ambientes'] == 0))]\n",
    "print(f\"Cantidad de filas restantes con Dormitorios == 0 y Ambientes == 0: {len(df[(df['Dormitorios'] == 0) & (df['Ambientes'] == 0)])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Banos\n",
    "Se eliminaron las filas que contenian mas de 7 y menos de 0 baños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Banos'] <= 7]\n",
    "df = df[df['Banos'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Ambientes\n",
    "Se eliminan las filas en las que ambientes < dormitorios y que ambientes < baños y aquellas con mas de 30 ambientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['Ambientes'] < df['Dormitorios']) | (df['Ambientes'] < df['Banos']))]\n",
    "df = df[~((df['Ambientes'] >= 30 )) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. SitioOrigen\n",
    "Se elimina la columna ya que no aporta información relevamte. 99% de los datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['SitioOrigen'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Antiguedad\n",
    "\n",
    "Se paso a números. Se eliminaron las filas con valores faltantes. Se eliminaron los valores mayores a 2024 y menores a 0. Para los que parecían ser años se hizo 2024 menos el año para obtener el número de antiguedad. Se paso a columna categorica del 1 al 5 (del más nuevo al más antiguo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Antiguedad'].notnull()]\n",
    "df['Antiguedad'] = df['Antiguedad'].replace(r'[^0-9.]', '', regex=True)\n",
    "df['Antiguedad'] = pd.to_numeric(df['Antiguedad'], errors='coerce').astype('Int64')\n",
    "df = df[~((df['Antiguedad'] > 2024) | (df['Antiguedad'] < 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_actual = 2024\n",
    "es_ano = df['Antiguedad'] >= 1700\n",
    "df.loc[es_ano, 'Antiguedad'] = ano_actual - df.loc[es_ano, 'Antiguedad']\n",
    "df['Antiguedad'] = df['Antiguedad'].astype(int)\n",
    "df = df[df['Antiguedad'] <= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_antiguedad(antiguedad):\n",
    "    if antiguedad <= 5:\n",
    "        return 1  \n",
    "    elif 5 < antiguedad <= 15:\n",
    "        return 2  \n",
    "    elif 15 < antiguedad <= 40:\n",
    "        return 3  \n",
    "    elif 40 < antiguedad <= 80:\n",
    "        return 4  \n",
    "    else:\n",
    "        return 5  \n",
    "\n",
    "df['Antiguedad'] = df['Antiguedad'].apply(lambda x: categorizar_antiguedad(x) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Cisterna\n",
    "Columna eliminada ya que la presencia de una cisterna probablemente tenga poco impacto directo en el precio de la propiedad y hay 58228 datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Cisterna'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Función que convierte a un valor apropiado las columnas que tienen como valores si, no ,1 ,0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasar_binarios(x):\n",
    "    df[x] = df[x].replace({\n",
    "        '0.0': 0, 'No': 0, '0': 0, '   0': 0, \n",
    "        '1.0': 1, '1': 1, 'Sí': 1\n",
    "    })\n",
    "    df[x] = pd.to_numeric(df[x], errors='coerce')\n",
    "    df[x] = df[x].fillna(0)\n",
    "    df[x].value_counts()\n",
    "x = ['AreaJuegosInfantiles','Chimenea','Ascensor','SalonFiestas','Seguridad','Pileta','Cocheras','PistaJogging','EstacionamientoVisitas','Lobby','AreaParrillas','CanchaTennis','AreaCine', 'LocalesComerciales', 'Amoblado','Jacuzzi', 'AccesoInternet','BusinessCenter', 'Gimnasio', 'Laundry', 'Calefaccion', 'SalonDeUsosMul', 'AireAC', 'Recepcion', 'Estacionamiento']\n",
    "for i in x:\n",
    "    pasar_binarios(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. SistContraIncendios\n",
    "Se elimina la columna ya que no tiene mucha info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['SistContraIncendios'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. ITE_TIPO_PROD\n",
    "Se paso a valores 0, 1 y 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ITE_TIPO_PROD'] = df['ITE_TIPO_PROD'].map({'N': 1, 'U': 2, 'S': 0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Year\n",
    "Se elimin la columna porque solo hay años 2022 y 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['year'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. ITE_ADD_STATE_NAME\n",
    "One hot para las 4 zonas.\n",
    "Capital Federal        143041\n",
    "Bs.As. G.B.A. Norte     43576\n",
    "Bs.As. G.B.A. Oeste     30029\n",
    "Bs.As. G.B.A. Sur       23885\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['ITE_ADD_STATE_NAME'], prefix='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. ITE_ADD_CITY_NAME\n",
    "Se agruparon las ciudades con menos de 1000 propiedades en la categoria 'otros' y se hizo one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1000\n",
    "city_counts = df['ITE_ADD_CITY_NAME'].value_counts()\n",
    "df['ITE_ADD_CITY_NAME'] = df['ITE_ADD_CITY_NAME'].apply(\n",
    "    lambda x: x if city_counts[x] >= threshold else 'Otros'\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['ITE_ADD_CITY_NAME'], prefix='city')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Precios\n",
    "\n",
    "Se detectó la presencia de outliers y se eliminaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 50000  \n",
    "upper_bound = 1700000  \n",
    "\n",
    "df = df[(df['precio_pesos_constantes'] >= lower_bound) & \n",
    "        (df['precio_pesos_constantes'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Agrego más features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más features relacionadas con los M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SConstrM2'] <= df['STotalM2']]\n",
    "\n",
    "df['SNoConstrM2'] = df['STotalM2'] - df['SConstrM2']\n",
    "df['SConstrRatio'] = df['SConstrM2'] / df['STotalM2']\n",
    "df['SNoConstrRatio'] = 1 - df['SConstrRatio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego una columan que contenga todos los servicios juntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['AreaJuegosInfantiles', 'Chimenea', 'Ascensor', 'SalonFiestas', 'Seguridad', \n",
    "     'Pileta', 'Cocheras', 'PistaJogging', 'EstacionamientoVisitas', 'Lobby', \n",
    "     'AreaParrillas', 'CanchaTennis', 'AreaCine', 'LocalesComerciales', 'Amoblado', \n",
    "     'Jacuzzi', 'AccesoInternet', 'BusinessCenter', 'Gimnasio', 'Laundry', \n",
    "     'Calefaccion', 'SalonDeUsosMul', 'AireAC', 'Recepcion', 'Estacionamiento']\n",
    "\n",
    "df['TieneServicios'] = df[x].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['ITE_ADD_NEIGHBORHOOD_NAME'])\n",
    "y = df['precio_pesos_constantes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoding = X_train.groupby('ITE_ADD_NEIGHBORHOOD_NAME')['precio_pesos_constantes'].mean()\n",
    "mean_m2 = X_train.groupby('ITE_ADD_NEIGHBORHOOD_NAME')['STotalM2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['mean_precio'] = X_train['ITE_ADD_NEIGHBORHOOD_NAME'].map(mean_encoding)\n",
    "X_train['mean_m2'] = X_train['ITE_ADD_NEIGHBORHOOD_NAME'].map(mean_m2)\n",
    "X_train['mean_p/m2'] = X_train['mean_precio'] / X_train['mean_m2']\n",
    "X_test['mean_precio'] = X_test['ITE_ADD_NEIGHBORHOOD_NAME'].map(mean_encoding)\n",
    "X_test['mean_m2'] = X_test['ITE_ADD_NEIGHBORHOOD_NAME'].map(mean_m2)\n",
    "X_test['mean_p/m2'] = X_test['mean_precio'] / X_test['mean_m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['mean_precio'], inplace=True)\n",
    "X_train.drop(columns=['mean_m2'], inplace=True)\n",
    "X_test.drop(columns=['mean_precio'], inplace=True)\n",
    "X_test.drop(columns=['mean_m2'], inplace=True)\n",
    "X_train.drop(columns=['ITE_ADD_NEIGHBORHOOD_NAME'], inplace=True)\n",
    "X_test.drop(columns=['ITE_ADD_NEIGHBORHOOD_NAME'], inplace=True)\n",
    "X_train.drop(columns = ['precio_pesos_constantes'], inplace=True)\n",
    "X_test.drop(columns = ['precio_pesos_constantes'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino cualquier fila que contenga un valor faltante. Unicamente de chequeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_filas_con_nan(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Elimina filas con valores NaN de los conjuntos X_train, X_test, y_train, y_test.\n",
    "    Asegura que las eliminaciones sean consistentes entre X e y.\n",
    "\n",
    "    Parámetros:\n",
    "        X_train (pd.DataFrame): Conjunto de entrenamiento de features.\n",
    "        X_test (pd.DataFrame): Conjunto de prueba de features.\n",
    "        y_train (pd.Series): Conjunto de entrenamiento de labels.\n",
    "        y_test (pd.Series): Conjunto de prueba de labels.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: X_train, X_test, y_train, y_test limpios.\n",
    "    \"\"\"\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    train = train.dropna()\n",
    "    X_train = train.iloc[:, :-1]  \n",
    "    y_train = train.iloc[:, -1]   \n",
    "\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    test = test.dropna()\n",
    "    X_test = test.iloc[:, :-1]  \n",
    "    y_test = test.iloc[:, -1]   \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = eliminar_filas_con_nan(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una vez finalizado el Preprocesamiento lo paso a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('/Users/victoria/Desktop/alquiler_procesado.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtrain.csv', index=False)\n",
    "X_test.to_csv('/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtest.csv', index=False)\n",
    "\n",
    "y_train.to_csv('/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytrain.csv', index=False)\n",
    "y_test.to_csv('/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
