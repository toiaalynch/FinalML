{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### División del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_toia = '/Users/victoria/Desktop/alquiler_procesado.csv'\n",
    "\n",
    "\n",
    "path_xtrain = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtrain.csv'\n",
    "path_xtest = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtest.csv'\n",
    "\n",
    "path_ytrain = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytrain.csv'\n",
    "path_ytest = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytest.csv'\n",
    "X_train = pd.read_csv(path_xtrain, low_memory=False)\n",
    "X_test = pd.read_csv(path_xtest, low_memory=False)\n",
    "y_train = pd.read_csv(path_ytrain, low_memory=False)\n",
    "y_test = pd.read_csv(path_ytest, low_memory=False)\n",
    "\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"path_benja = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado.csv'\\ndf = pd.read_csv(path_benja, low_memory=False)\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"path_benja = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado.csv'\n",
    "df = pd.read_csv(path_benja, low_memory=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22100, 68)\n",
      "X_test shape: (5517, 68)\n",
      "y_train shape: (22100,)\n",
      "y_test shape: (5517,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"X = df.drop(columns=['precio_pesos_constantes'])  \n",
    "y = df['precio_pesos_constantes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\"\"\"\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hago función para imprimir métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    # Calcular métricas\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    # Crear DataFrame con las métricas\n",
    "    metrics = {\n",
    "        'MAE': [mae_train, mae_test],\n",
    "        'R²': [r2_train, r2_test],\n",
    "        'MSE': [mse_train, mse_test],\n",
    "        'RMSE': [rmse_train, rmse_test]\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics, index=['Entrenamiento', 'Prueba'])\n",
    "\n",
    "    print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE           RMSE\n",
      "Entrenamiento  54294.114341  0.624004  1.251644e+10  111876.897108\n",
      "Prueba         53658.229879  0.659845  1.236731e+10  111208.404642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = linear_model.predict(X_train)\n",
    "y_pred_test = linear_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.3s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.3s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.2s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.2s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.9s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   6.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.9s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.8s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.1s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.9s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   7.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.1s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   4.8s\n",
      "Mejores Hiperparámetros Encontrados:\n",
      "{'learning_rate': 0.5, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MSE en conjunto de prueba: 2211727261.0476\n",
      "MAE en conjunto de prueba: 19310.3293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "# Suprimir warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Ignorar warnings generales\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Crear el modelo base\n",
    "gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Definir los hiperparámetros a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [80, 100],        # Número de árboles en el ensemble\n",
    "    'learning_rate': [0.5, 0.6],    # Tasa de aprendizaje\n",
    "    'max_depth': [5, 6],\n",
    "    'min_samples_split': [2,3],\n",
    "    'min_samples_leaf': [1,2]               # Máxima profundidad de los árboles         \n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gbr_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='neg_mean_squared_error',  # Métrica para evaluar\n",
    "    cv=3,                             # Número de folds para validación cruzada\n",
    "    verbose=2,                        # Ver progreso\n",
    "    n_jobs=-1                         # Paralelización\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores Hiperparámetros Encontrados:\")\n",
    "print(best_params)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_gbr_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred_test = best_gbr_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MSE en conjunto de prueba: {mse_test:.4f}\")\n",
    "print(f\"MAE en conjunto de prueba: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE          RMSE\n",
      "Entrenamiento  13927.429719  0.985859  4.707220e+08  21696.129137\n",
      "Prueba         19310.329274  0.939168  2.211727e+09  47029.004466\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = best_gbr_model.predict(X_train)\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE          RMSE\n",
      "Entrenamiento   7725.735946  0.993649  2.114227e+08  14540.381264\n",
      "Prueba         16022.650226  0.923034  2.798322e+09  52899.164718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo Gradient Boosting\n",
    "gbr_model = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.6, \n",
    "    max_depth=7, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_train = gbr_model.predict(X_train)\n",
    "y_pred_test = gbr_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - loss: 52004253696.0000 - mae: 140224.5938 - val_loss: 42578427904.0000 - val_mae: 82611.3125\n",
      "Epoch 2/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - loss: 39477403648.0000 - mae: 79375.9453 - val_loss: 37659680768.0000 - val_mae: 80015.3438\n",
      "Epoch 3/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522us/step - loss: 33353975808.0000 - mae: 79202.3594 - val_loss: 37135163392.0000 - val_mae: 81067.2656\n",
      "Epoch 4/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471us/step - loss: 33221328896.0000 - mae: 79311.8281 - val_loss: 36653666304.0000 - val_mae: 81082.7188\n",
      "Epoch 5/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - loss: 31446482944.0000 - mae: 78449.4531 - val_loss: 36167553024.0000 - val_mae: 80988.8359\n",
      "Epoch 6/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - loss: 31572084736.0000 - mae: 78667.0625 - val_loss: 35652341760.0000 - val_mae: 80951.0469\n",
      "Epoch 7/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - loss: 33266561024.0000 - mae: 80969.8516 - val_loss: 35099041792.0000 - val_mae: 80595.3047\n",
      "Epoch 8/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - loss: 33308866560.0000 - mae: 81043.5859 - val_loss: 34506600448.0000 - val_mae: 80185.0703\n",
      "Epoch 9/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481us/step - loss: 32319449088.0000 - mae: 80191.9453 - val_loss: 33847830528.0000 - val_mae: 79445.5156\n",
      "Epoch 10/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460us/step - loss: 32885624832.0000 - mae: 80363.3594 - val_loss: 33118945280.0000 - val_mae: 79776.5938\n",
      "Epoch 11/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - loss: 29854418944.0000 - mae: 78587.6016 - val_loss: 32318617600.0000 - val_mae: 78624.2969\n",
      "Epoch 12/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step - loss: 29574989824.0000 - mae: 78175.6016 - val_loss: 31396894720.0000 - val_mae: 79036.2891\n",
      "Epoch 13/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 459us/step - loss: 27364265984.0000 - mae: 77064.7656 - val_loss: 30428289024.0000 - val_mae: 78512.4141\n",
      "Epoch 14/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - loss: 29620834304.0000 - mae: 79444.7109 - val_loss: 29376221184.0000 - val_mae: 78117.5000\n",
      "Epoch 15/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - loss: 26528503808.0000 - mae: 77253.7656 - val_loss: 28237998080.0000 - val_mae: 76940.9297\n",
      "Epoch 16/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - loss: 25987876864.0000 - mae: 75700.2500 - val_loss: 27060105216.0000 - val_mae: 76527.2344\n",
      "Epoch 17/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step - loss: 24655577088.0000 - mae: 76088.4375 - val_loss: 25818880000.0000 - val_mae: 75948.3906\n",
      "Epoch 18/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - loss: 24318068736.0000 - mae: 75748.5312 - val_loss: 24570038272.0000 - val_mae: 75444.8203\n",
      "Epoch 19/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step - loss: 21963159552.0000 - mae: 73871.7031 - val_loss: 23297789952.0000 - val_mae: 74814.5938\n",
      "Epoch 20/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452us/step - loss: 23703902208.0000 - mae: 75748.1172 - val_loss: 22109272064.0000 - val_mae: 72939.4453\n",
      "Epoch 21/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457us/step - loss: 20547903488.0000 - mae: 72307.9766 - val_loss: 20882280448.0000 - val_mae: 73012.1484\n",
      "Epoch 22/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - loss: 19574120448.0000 - mae: 71269.5078 - val_loss: 19764209664.0000 - val_mae: 70795.1250\n",
      "Epoch 23/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 477us/step - loss: 19097155584.0000 - mae: 69808.5938 - val_loss: 18737686528.0000 - val_mae: 68850.8359\n",
      "Epoch 24/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - loss: 18759395328.0000 - mae: 68849.7266 - val_loss: 17814407168.0000 - val_mae: 68540.3203\n",
      "Epoch 25/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - loss: 17782288384.0000 - mae: 67955.9531 - val_loss: 17052719104.0000 - val_mae: 65754.0625\n",
      "Epoch 26/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - loss: 18248845312.0000 - mae: 66179.6562 - val_loss: 16410002432.0000 - val_mae: 64833.3438\n",
      "Epoch 27/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - loss: 16989452288.0000 - mae: 65426.5000 - val_loss: 15872801792.0000 - val_mae: 62817.4492\n",
      "Epoch 28/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - loss: 17855537152.0000 - mae: 64887.5156 - val_loss: 15445638144.0000 - val_mae: 61525.4453\n",
      "Epoch 29/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step - loss: 16007947264.0000 - mae: 62094.2383 - val_loss: 15102403584.0000 - val_mae: 60372.6797\n",
      "Epoch 30/30\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - loss: 16055129088.0000 - mae: 61978.9297 - val_loss: 14827123712.0000 - val_mae: 59795.6172\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267us/step\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step\n",
      "                        MAE        R²           MSE           RMSE\n",
      "Entrenamiento  60451.894189  0.529062  1.567694e+10  125207.587711\n",
      "Prueba         59795.651779  0.592189  1.482712e+10  121766.676540\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compilar el modelo con tasa de aprendizaje ajustada\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "nn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = nn_model.fit(X_train_scaled, y_train, epochs=30, batch_size=16, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Predicciones\n",
    "y_pred_train = nn_model.predict(X_train_scaled).ravel()\n",
    "y_pred_test = nn_model.predict(X_test_scaled).ravel()\n",
    "\n",
    "# Métricas\n",
    "print_metrics(y_train, y_pred_train.ravel(), y_test, y_pred_test.ravel())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
