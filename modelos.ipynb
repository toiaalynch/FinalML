{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_xtrain = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtrain.csv'\n",
    "path_xtest = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_Xtest.csv'\n",
    "\n",
    "path_ytrain = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytrain.csv'\n",
    "path_ytest = '/Users/benjavitale/Documents/ML/TP_F/alquiler_procesado_ytest.csv'\n",
    "X_train = pd.read_csv(path_xtrain, low_memory=False)\n",
    "X_test = pd.read_csv(path_xtest, low_memory=False)\n",
    "y_train = pd.read_csv(path_ytrain, low_memory=False)\n",
    "y_test = pd.read_csv(path_ytest, low_memory=False)\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para imprimir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    metrics = {\n",
    "        'MAE': [mae_train, mae_test],\n",
    "        'R²': [r2_train, r2_test],\n",
    "        'MSE': [mse_train, mse_test],\n",
    "        'RMSE': [rmse_train, rmse_test]\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics, index=['Entrenamiento', 'Prueba'])\n",
    "\n",
    "    print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE           RMSE\n",
      "Entrenamiento  54278.960428  0.624003  1.251647e+10  111877.017513\n",
      "Prueba         53645.717510  0.659836  1.236765e+10  111209.930880\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_train = linear_model.predict(X_train_scaled)\n",
    "y_pred_test = linear_model.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting con Grind Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.7s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.7s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.0s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   3.7s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.1s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   3.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   3.8s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.7s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.1s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.2s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.7s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.6s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.5s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.8s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.7s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.9s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.0s\n",
      "[CV] END learning_rate=0.5, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   4.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.2s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.5s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   4.8s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   5.8s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.7s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.8s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   6.1s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.7s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=80; total time=   5.2s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.2s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=1, min_samples_split=3, n_estimators=100; total time=   6.6s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=80; total time=   5.4s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.5s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   5.0s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=80; total time=   4.9s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   6.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.6s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   5.3s\n",
      "[CV] END learning_rate=0.6, max_depth=6, min_samples_leaf=2, min_samples_split=3, n_estimators=100; total time=   4.8s\n",
      "Mejores Hiperparámetros Encontrados:\n",
      "{'learning_rate': 0.5, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MSE en conjunto de prueba: 2211727261.0476\n",
      "MAE en conjunto de prueba: 19310.3293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "gbr_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [80, 100],        \n",
    "    'learning_rate': [0.5, 0.6],    \n",
    "    'max_depth': [5, 6],\n",
    "    'min_samples_split': [2,3],\n",
    "    'min_samples_leaf': [1,2]                       \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gbr_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='neg_mean_squared_error',  \n",
    "    cv=3,                             \n",
    "    verbose=2,                      \n",
    "    n_jobs=-1                         \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores Hiperparámetros Encontrados:\")\n",
    "print(best_params)\n",
    "\n",
    "best_gbr_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_test = best_gbr_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MSE en conjunto de prueba: {mse_test:.4f}\")\n",
    "print(f\"MAE en conjunto de prueba: {mae_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE          RMSE\n",
      "Entrenamiento  13927.429719  0.985859  4.707220e+08  21696.129137\n",
      "Prueba         19310.329274  0.939168  2.211727e+09  47029.004466\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = best_gbr_model.predict(X_train)\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        MAE        R²           MSE          RMSE\n",
      "Entrenamiento   7725.735946  0.993649  2.114227e+08  14540.381264\n",
      "Prueba         16022.650226  0.923034  2.798322e+09  52899.164718\n"
     ]
    }
   ],
   "source": [
    "gbr_model = GradientBoostingRegressor(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.6, \n",
    "    max_depth=7, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = gbr_model.predict(X_train)\n",
    "y_pred_test = gbr_model.predict(X_test)\n",
    "\n",
    "print_metrics(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 676us/step - loss: 44505706496.0000 - mae: 111676.1172 - val_loss: 35176325120.0000 - val_mae: 79267.8516\n",
      "Epoch 2/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - loss: 29821218816.0000 - mae: 80143.5703 - val_loss: 23249221632.0000 - val_mae: 73759.3281\n",
      "Epoch 3/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 20605067264.0000 - mae: 72050.7344 - val_loss: 14467225600.0000 - val_mae: 57519.2266\n",
      "Epoch 4/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - loss: 15272458240.0000 - mae: 61561.0625 - val_loss: 13865213952.0000 - val_mae: 54774.9922\n",
      "Epoch 5/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - loss: 15660104704.0000 - mae: 61311.3203 - val_loss: 12630452224.0000 - val_mae: 54023.7773\n",
      "Epoch 6/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612us/step - loss: 14557529088.0000 - mae: 59382.4062 - val_loss: 13243858944.0000 - val_mae: 52914.0742\n",
      "Epoch 7/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - loss: 15575348224.0000 - mae: 61054.0195 - val_loss: 11932525568.0000 - val_mae: 53053.6680\n",
      "Epoch 8/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 14290405376.0000 - mae: 59265.6289 - val_loss: 11984107520.0000 - val_mae: 51330.8555\n",
      "Epoch 9/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 14022586368.0000 - mae: 59229.2930 - val_loss: 11371560960.0000 - val_mae: 52101.3125\n",
      "Epoch 10/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - loss: 12630828032.0000 - mae: 57259.1875 - val_loss: 11205381120.0000 - val_mae: 52622.6562\n",
      "Epoch 11/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 14055443456.0000 - mae: 59320.6836 - val_loss: 11180308480.0000 - val_mae: 50946.6758\n",
      "Epoch 12/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 12225512448.0000 - mae: 56884.3398 - val_loss: 10753020928.0000 - val_mae: 50540.6211\n",
      "Epoch 13/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 12448205824.0000 - mae: 57804.5273 - val_loss: 10660358144.0000 - val_mae: 50245.3242\n",
      "Epoch 14/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 13440273408.0000 - mae: 58135.8750 - val_loss: 10337548288.0000 - val_mae: 50916.0078\n",
      "Epoch 15/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - loss: 13431718912.0000 - mae: 58099.0898 - val_loss: 10383692800.0000 - val_mae: 50320.3555\n",
      "Epoch 16/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - loss: 12065473536.0000 - mae: 56956.9570 - val_loss: 10269967360.0000 - val_mae: 49790.2188\n",
      "Epoch 17/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 12448440320.0000 - mae: 57513.1406 - val_loss: 10195961856.0000 - val_mae: 51175.0781\n",
      "Epoch 18/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - loss: 12672865280.0000 - mae: 57030.0898 - val_loss: 10649105408.0000 - val_mae: 50020.3086\n",
      "Epoch 19/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - loss: 11559158784.0000 - mae: 56104.0508 - val_loss: 9790133248.0000 - val_mae: 49010.3594\n",
      "Epoch 20/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - loss: 10828484608.0000 - mae: 55228.7578 - val_loss: 9712307200.0000 - val_mae: 49376.0156\n",
      "Epoch 21/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 11185290240.0000 - mae: 55030.2031 - val_loss: 9745456128.0000 - val_mae: 49357.0664\n",
      "Epoch 22/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - loss: 11848975360.0000 - mae: 56377.2500 - val_loss: 9452020736.0000 - val_mae: 48375.2383\n",
      "Epoch 23/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - loss: 11557745664.0000 - mae: 55278.4805 - val_loss: 9396539392.0000 - val_mae: 50256.7500\n",
      "Epoch 24/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - loss: 11506222080.0000 - mae: 56433.1797 - val_loss: 9498945536.0000 - val_mae: 49412.2070\n",
      "Epoch 25/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 11245377536.0000 - mae: 56121.9531 - val_loss: 9371032576.0000 - val_mae: 48315.0469\n",
      "Epoch 26/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - loss: 10595723264.0000 - mae: 54583.7148 - val_loss: 9285654528.0000 - val_mae: 48929.1250\n",
      "Epoch 27/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - loss: 11204556800.0000 - mae: 55037.3711 - val_loss: 9479665664.0000 - val_mae: 48464.7383\n",
      "Epoch 28/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 10891059200.0000 - mae: 55098.9375 - val_loss: 9336057856.0000 - val_mae: 49137.2109\n",
      "Epoch 29/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - loss: 11138028544.0000 - mae: 55258.7422 - val_loss: 9091788800.0000 - val_mae: 48910.3047\n",
      "Epoch 30/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - loss: 10803254272.0000 - mae: 55322.9922 - val_loss: 9175913472.0000 - val_mae: 48806.8789\n",
      "Epoch 31/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - loss: 12437770240.0000 - mae: 57151.0859 - val_loss: 9225609216.0000 - val_mae: 48368.1875\n",
      "Epoch 32/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 12363491328.0000 - mae: 56723.2305 - val_loss: 9094856704.0000 - val_mae: 48317.7539\n",
      "Epoch 33/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - loss: 11069889536.0000 - mae: 55137.1016 - val_loss: 8718226432.0000 - val_mae: 48571.8398\n",
      "Epoch 34/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - loss: 11460492288.0000 - mae: 55133.5391 - val_loss: 8860664832.0000 - val_mae: 49701.7539\n",
      "Epoch 35/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - loss: 10637052928.0000 - mae: 55096.2578 - val_loss: 9261408256.0000 - val_mae: 48816.9258\n",
      "Epoch 36/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - loss: 11776581632.0000 - mae: 56253.0156 - val_loss: 9135773696.0000 - val_mae: 48464.0000\n",
      "Epoch 37/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - loss: 11424424960.0000 - mae: 55599.5938 - val_loss: 8793565184.0000 - val_mae: 47996.3594\n",
      "Epoch 38/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - loss: 10514166784.0000 - mae: 54056.4336 - val_loss: 8980893696.0000 - val_mae: 48389.5391\n",
      "Epoch 39/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - loss: 11958212608.0000 - mae: 55160.5547 - val_loss: 8852710400.0000 - val_mae: 48033.1523\n",
      "Epoch 40/40\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - loss: 10580889600.0000 - mae: 54198.6211 - val_loss: 8660166656.0000 - val_mae: 48559.3711\n",
      "\u001b[1m691/691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "                        MAE        R²           MSE          RMSE\n",
      "Entrenamiento  49774.442132  0.723178  9.215046e+09  95995.028841\n",
      "Prueba         48559.383531  0.761808  8.660164e+09  93060.001508\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.00001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.00001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.00001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.00001)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "nn_model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "history = nn_model.fit(X_train_scaled, y_train, epochs=40, batch_size=16, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "y_pred_train = nn_model.predict(X_train_scaled).ravel()\n",
    "y_pred_test = nn_model.predict(X_test_scaled).ravel()\n",
    "\n",
    "print_metrics(y_train, y_pred_train.ravel(), y_test, y_pred_test.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Supongamos que tienes un MinMaxScaler llamado 'scaler'\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Guarda el objeto de normalización en un archivo\n",
    "joblib.dump(nn_model,'nn_model.pkl')\n",
    "joblib.dump(best_gbr_model,'best_gbr_model.pkl')\n",
    "joblib.dump(linear_model,'linear_model.pkl')\n",
    "joblib.dump(X_train,'X_train.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
